
//  BatchedRequestManager.swift
//  CyntientOps v6.0
//
//  ‚úÖ STREAM B IMPLEMENTATION: Efficient API request batching
//  ‚úÖ FEATURES: Automatic batching, retry logic, priority queuing
//  ‚úÖ THREAD-SAFE: Actor-based implementation
//

import Foundation
import Combine

// MARK: - API Request Types

public struct APIRequest: Identifiable, Codable {
    public let id: String
    public let endpoint: String
    public let method: HTTPMethod
    public let headers: [String: String]
    public let body: Data?
    public let priority: RequestPriority
    public let retryCount: Int
    public let createdAt: Date
    
    public enum HTTPMethod: String, Codable {
        case get = "GET"
        case post = "POST"
        case put = "PUT"
        case patch = "PATCH"
        case delete = "DELETE"
    }
    
    public enum RequestPriority: Int, Codable, Comparable {
        case low = 0
        case normal = 1
        case high = 2
        case critical = 3
        
        public static func < (lhs: RequestPriority, rhs: RequestPriority) -> Bool {
            lhs.rawValue < rhs.rawValue
        }
    }
    
    public init(
        id: String = UUID().uuidString,
        endpoint: String,
        method: HTTPMethod,
        headers: [String: String] = [:],
        body: Data? = nil,
        priority: RequestPriority = .normal,
        retryCount: Int = 0,
        createdAt: Date = Date()
    ) {
        self.id = id
        self.endpoint = endpoint
        self.method = method
        self.headers = headers
        self.body = body
        self.priority = priority
        self.retryCount = retryCount
        self.createdAt = createdAt
    }
}

public struct APIResponse {
    public let requestId: String
    public let statusCode: Int
    public let data: Data?
    public let headers: [String: String]
    public let error: Error?
    
    public var isSuccess: Bool {
        (200...299).contains(statusCode)
    }
}

public struct BatchedAPIResponse {
    public let responses: [APIResponse]
    public let successCount: Int
    public let failureCount: Int
    public let batchId: String
    public let processingTime: TimeInterval
}

// MARK: - Batched Request Manager

public actor BatchedRequestManager {
    // MARK: - Properties
    
    private var pendingRequests: [APIRequest] = []
    private let batchSize: Int
    private let batchDelay: TimeInterval
    private var batchTimer: Task<Void, Never>?
    private let maxRetries: Int
    private let retryDelay: TimeInterval
    
    // Analytics
    private var totalRequestsProcessed: Int = 0
    private var totalBatchesSent: Int = 0
    private var averageResponseTime: TimeInterval = 0
    
    // Network monitoring
    private let networkMonitor: NetworkMonitor
    
    // Publishers
    private let batchProcessedSubject = PassthroughSubject<BatchedAPIResponse, Never>()
    public var batchProcessedPublisher: AnyPublisher<BatchedAPIResponse, Never> {
        batchProcessedSubject.eraseToAnyPublisher()
    }
    
    // Configuration
    private let baseURL: String
    private let session: URLSession
    private let encoder = JSONEncoder()
    private let decoder = JSONDecoder()
    
    // MARK: - Initialization
    
    public init(
        baseURL: String,
        batchSize: Int = 50,
        batchDelay: TimeInterval = 0.5,
        maxRetries: Int = 3,
        retryDelay: TimeInterval = 2.0,
        session: URLSession = .shared
    ) {
        self.baseURL = baseURL
        self.batchSize = batchSize
        self.batchDelay = batchDelay
        self.maxRetries = maxRetries
        self.retryDelay = retryDelay
        self.session = session
        self.networkMonitor = NetworkMonitor.shared
        
        // Setup encoder/decoder
        encoder.dateEncodingStrategy = .iso8601
        decoder.dateDecodingStrategy = .iso8601
    }
    
    // MARK: - Public Methods
    
    /// Add a request to the batch queue
    public func addRequest(_ request: APIRequest) async {
        // Check network status first
        guard await networkMonitor.isConnected else {
            print("‚ö†Ô∏è Network offline, queueing request: \(request.endpoint)")
            await queueForOffline(request)
            return
        }
        
        // Add to pending requests (sorted by priority)
        pendingRequests.append(request)
        pendingRequests.sort { $0.priority > $1.priority }
        
        // Check if we should process immediately
        if pendingRequests.count >= batchSize {
            await processBatch()
        } else {
            // Schedule batch processing
            await scheduleBatchProcessing()
        }
    }
    
    /// Force process all pending requests
    public func flush() async {
        await processBatch()
    }
    
    /// Get current queue status
    public func getQueueStatus() async -> BatchQueueStatus {
        BatchQueueStatus(
            pendingCount: pendingRequests.count,
            isProcessing: batchTimer != nil,
            totalProcessed: totalRequestsProcessed,
            averageResponseTime: averageResponseTime
        )
    }
    
    /// Cancel all pending requests
    public func cancelAllPendingRequests() async {
        pendingRequests.removeAll()
        batchTimer?.cancel()
        batchTimer = nil
    }
    
    // MARK: - Private Methods
    
    private func scheduleBatchProcessing() async {
        // Cancel existing timer
        batchTimer?.cancel()
        
        // Create new timer
        batchTimer = Task {
            try? await Task.sleep(nanoseconds: UInt64(batchDelay * 1_000_000_000))
            
            guard !Task.isCancelled else { return }
            
            await processBatch()
        }
    }
    
    private func processBatch() async {
        // Cancel timer
        batchTimer?.cancel()
        batchTimer = nil
        
        // Get batch to process
        guard !pendingRequests.isEmpty else { return }
        
        let batch = Array(pendingRequests.prefix(batchSize))
        pendingRequests.removeFirst(min(batchSize, pendingRequests.count))
        
        // Send batch
        await sendBatch(batch)
        
        // Process remaining requests if any
        if !pendingRequests.isEmpty {
            await scheduleBatchProcessing()
        }
    }
    
    private func sendBatch(_ batch: [APIRequest]) async {
        let batchId = UUID().uuidString
        let startTime = Date()
        
        print("üì§ Sending batch \(batchId) with \(batch.count) requests")
        
        // Create batch request
        let batchRequest = BatchRequest(
            batchId: batchId,
            requests: batch,
            timestamp: Date()
        )
        
        do {
            // Encode batch
            let batchData = try encoder.encode(batchRequest)
            
            // Create URL request
            var urlRequest = URLRequest(url: URL(string: "\(baseURL)/batch")!)
            urlRequest.httpMethod = "POST"
            urlRequest.httpBody = batchData
            urlRequest.setValue("application/json", forHTTPHeaderField: "Content-Type")
            urlRequest.setValue(batchId, forHTTPHeaderField: "X-Batch-ID")
            
            // Send request
            let (data, response) = try await session.data(for: urlRequest)
            
            // Process response
            let httpResponse = response as? HTTPURLResponse
            let statusCode = httpResponse?.statusCode ?? 0
            
            if (200...299).contains(statusCode) {
                // Parse batch response
                let batchResponse = try decoder.decode(BatchResponse.self, from: data)
                await handleBatchResponse(batchResponse, originalBatch: batch, batchId: batchId, startTime: startTime)
            } else {
                // Handle batch failure
                await handleBatchFailure(batch, statusCode: statusCode, batchId: batchId)
            }
            
        } catch {
            print("‚ùå Batch \(batchId) failed: \(error)")
            await handleBatchError(batch, error: error, batchId: batchId)
        }
        
        // Update metrics
        totalBatchesSent += 1
        totalRequestsProcessed += batch.count
    }
    
    private func handleBatchResponse(
        _ response: BatchResponse,
        originalBatch: [APIRequest],
        batchId: String,
        startTime: Date
    ) async {
        let processingTime = Date().timeIntervalSince(startTime)
        var apiResponses: [APIResponse] = []
        var failedRequests: [APIRequest] = []
        
        // Process individual responses
        for (index, result) in response.results.enumerated() {
            guard index < originalBatch.count else { continue }
            let request = originalBatch[index]
            
            let apiResponse = APIResponse(
                requestId: request.id,
                statusCode: result.statusCode,
                data: result.data,
                headers: result.headers,
                error: result.error.map { NSError(domain: "BatchAPI", code: result.statusCode, userInfo: [NSLocalizedDescriptionKey: $0]) }
            )
            
            apiResponses.append(apiResponse)
            
            // Check if retry needed
            if !apiResponse.isSuccess && request.retryCount < maxRetries {
                var retryRequest = request
                retryRequest = APIRequest(
                    id: request.id,
                    endpoint: request.endpoint,
                    method: request.method,
                    headers: request.headers,
                    body: request.body,
                    priority: request.priority,
                    retryCount: request.retryCount + 1,
                    createdAt: request.createdAt
                )
                failedRequests.append(retryRequest)
            }
        }
        
        // Retry failed requests
        if !failedRequests.isEmpty {
            Task {
                try? await Task.sleep(nanoseconds: UInt64(retryDelay * 1_000_000_000))
                for request in failedRequests {
                    await addRequest(request)
                }
            }
        }
        
        // Update average response time
        let currentAverage = averageResponseTime
        let totalRequests = Double(totalRequestsProcessed)
        averageResponseTime = (currentAverage * (totalRequests - Double(originalBatch.count)) + processingTime) / totalRequests
        
        // Publish batch response
        let batchedResponse = BatchedAPIResponse(
            responses: apiResponses,
            successCount: apiResponses.filter { $0.isSuccess }.count,
            failureCount: apiResponses.filter { !$0.isSuccess }.count,
            batchId: batchId,
            processingTime: processingTime
        )
        
        batchProcessedSubject.send(batchedResponse)
        
        print("‚úÖ Batch \(batchId) completed: \(batchedResponse.successCount) success, \(batchedResponse.failureCount) failed")
    }
    
    private func handleBatchFailure(_ batch: [APIRequest], statusCode: Int, batchId: String) async {
        print("‚ö†Ô∏è Batch \(batchId) failed with status: \(statusCode)")
        
        // Retry all requests if server error
        if (500...599).contains(statusCode) {
            for request in batch where request.retryCount < maxRetries {
                var retryRequest = request
                retryRequest = APIRequest(
                    id: request.id,
                    endpoint: request.endpoint,
                    method: request.method,
                    headers: request.headers,
                    body: request.body,
                    priority: request.priority,
                    retryCount: request.retryCount + 1,
                    createdAt: request.createdAt
                )
                await addRequest(retryRequest)
            }
        }
    }
    
    private func handleBatchError(_ batch: [APIRequest], error: Error, batchId: String) async {
        // Check if network error
        if (error as NSError).code == NSURLErrorNotConnectedToInternet {
            // Queue all requests for offline
            for request in batch {
                await queueForOffline(request)
            }
        } else {
            // Retry with exponential backoff
            for request in batch where request.retryCount < maxRetries {
                let backoffDelay = retryDelay * pow(2.0, Double(request.retryCount))
                
                Task {
                    try? await Task.sleep(nanoseconds: UInt64(backoffDelay * 1_000_000_000))
                    
                    var retryRequest = request
                    retryRequest = APIRequest(
                        id: request.id,
                        endpoint: request.endpoint,
                        method: request.method,
                        headers: request.headers,
                        body: request.body,
                        priority: request.priority,
                        retryCount: request.retryCount + 1,
                        createdAt: request.createdAt
                    )
                    await addRequest(retryRequest)
                }
            }
        }
    }
    
    private func queueForOffline(_ request: APIRequest) async {
        // This would integrate with your offline sync queue
        // For now, we'll store in a separate array
        print("üì± Queuing request for offline: \(request.endpoint)")
    }
}

// MARK: - Supporting Types

public struct BatchQueueStatus {
    public let pendingCount: Int
    public let isProcessing: Bool
    public let totalProcessed: Int
    public let averageResponseTime: TimeInterval
}

private struct BatchRequest: Codable {
    let batchId: String
    let requests: [APIRequest]
    let timestamp: Date
}

private struct BatchResponse: Codable {
    let batchId: String
    let results: [BatchResult]
}

private struct BatchResult: Codable {
    let requestId: String
    let statusCode: Int
    let data: Data?
    let headers: [String: String]
    let error: String?
}
